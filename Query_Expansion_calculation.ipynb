{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Query_Expansion calculation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UphAwEWPHKM6",
        "colab_type": "text"
      },
      "source": [
        "**Implementation of Query Expansion Algorithm**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J36j4TUzHCsv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import xml.dom.minidom\n",
        "import xml.etree.ElementTree as ET\n",
        "import nltk\n",
        "import pandas as pd\n",
        "import os\n",
        "import glob\n",
        "import xml.etree.ElementTree as ET\n",
        "import nltk\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59rSPm1fHIFP",
        "colab_type": "text"
      },
      "source": [
        "Extracting Queries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adWiT46RHCtN",
        "colab_type": "code",
        "colab": {},
        "outputId": "ffcc22b3-db85-4b7a-b259-dfe7705507d1"
      },
      "source": [
        "os.chdir('C:/Users/Subham/IRLab/Assignment3/FIRE_Dataset_EN_2010')\n",
        "doc=xml.dom.minidom.parse('C:/Users/Subham/IRLab/Assignment3/FIRE_Dataset_EN_2010/en.topics.76-125.2010.txt')\n",
        "query_ids=doc.getElementsByTagName(\"num\")\n",
        "print(query_ids.length)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eervN7tqHCtl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file=open('C:/Users/Subham/IRLab/Assignment3/FIRE_Dataset_EN_2010/en.topics.76-125.2010.txt','r')\n",
        "tree=ET.parse(file);\n",
        "root=tree.getroot();\n",
        "queries=[]\n",
        "for child in root.iter('desc'):\n",
        "    queries.append(child.text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVBsV5r_HVuD",
        "colab_type": "text"
      },
      "source": [
        "Removing punctuations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcHBvqzjHCt5",
        "colab_type": "code",
        "colab": {},
        "outputId": "d39b825c-9536-4981-8fb1-95a568f5ce15"
      },
      "source": [
        "punctuations = '''!()[]{};:\"\\,<>./?@#$%^&*_~-'''\n",
        "queries2=[];\n",
        "for sent in queries:\n",
        "    s=\"\"\n",
        "    for x in sent:\n",
        "        if(x not in punctuations):\n",
        "            s=s+x;\n",
        "    queries2.append(s);\n",
        "\n",
        "\n",
        "queries=queries2;\n",
        "queries2=[]\n",
        "print(queries[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Reasons behind the protests by Meena leaders against the\n",
            "inclusion of Gurjars in the Scheduled Tribes\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggBr3T_LHCuQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "queries2=[]\n",
        "for sent in queries:\n",
        "    s=\"\"\n",
        "    sent=' '.join(sent.split())\n",
        "    queries2.append(sent);\n",
        "\n",
        "queries=queries2;\n",
        "queries2=[]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2um8GXY0Hayx",
        "colab_type": "text"
      },
      "source": [
        "Conversion to LowerCase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_u7HcEXNHCum",
        "colab_type": "code",
        "colab": {},
        "outputId": "6ec4e8f3-639b-4d65-a9c4-6a9ca61995c5"
      },
      "source": [
        "queries2=[]\n",
        "for sent in queries:\n",
        "    sent=sent.lower()\n",
        "    queries2.append(sent);\n",
        "\n",
        "queries=queries2;\n",
        "queries2=[]\n",
        "print(queries[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "reasons behind the protests by meena leaders against the inclusion of gurjars in the scheduled tribes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxpbHvGYHdMN",
        "colab_type": "text"
      },
      "source": [
        "Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcO7WQg2HCuz",
        "colab_type": "code",
        "colab": {},
        "outputId": "15eff382-3334-4608-d325-f0cc8c1fd0cc"
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "queries2=[]\n",
        "for sent in queries:\n",
        "    sent=word_tokenize(sent)\n",
        "    queries2.append(sent);\n",
        "\n",
        "queries=queries2;\n",
        "queries2=[]\n",
        "print(queries[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['reasons', 'behind', 'the', 'protests', 'by', 'meena', 'leaders', 'against', 'the', 'inclusion', 'of', 'gurjars', 'in', 'the', 'scheduled', 'tribes']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQr6iqWzHe3f",
        "colab_type": "text"
      },
      "source": [
        "Removal of StopWords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsKVc8txHCu9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "stop_words=set(stopwords.words(\"english\"));\n",
        "\n",
        "queries2=[]\n",
        "for sent in queries:\n",
        "    s=[];\n",
        "    for word in sent:\n",
        "        if(word not in stop_words):\n",
        "            s.append(word);\n",
        "    queries2.append(s);\n",
        "\n",
        "queries=queries2;\n",
        "queries2=[]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJ6AT4AvHgoe",
        "colab_type": "text"
      },
      "source": [
        "Lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWz3yrp2HCvE",
        "colab_type": "code",
        "colab": {},
        "outputId": "9f95f511-3e31-46cf-a164-f05a398ad3ff"
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "lemmatizer=WordNetLemmatizer();\n",
        "queries2=[]\n",
        "for sent in queries:\n",
        "    s=[];\n",
        "    for word in sent:\n",
        "        s.append(lemmatizer.lemmatize(word));\n",
        "    queries2.append(s);\n",
        "\n",
        "queries=queries2;\n",
        "queries2=[]\n",
        "print(queries[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['reason', 'behind', 'protest', 'meena', 'leader', 'inclusion', 'gurjars', 'scheduled', 'tribe']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWfnCE9sHCvM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.corpus import wordnet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wImLKFhiHi79",
        "colab_type": "text"
      },
      "source": [
        "Synonyms calculation word by word and appending it to the respective word"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arht9MKmHCvT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "queries_exp=[]\n",
        "for i in range(50):\n",
        "    words=queries[i]\n",
        "    qexp=[]\n",
        "    for x in words:\n",
        "        #print(\"----\")\n",
        "        #print(x)\n",
        "        try:\n",
        "            syn=wordnet.synsets(x)[0]\n",
        "            lemmas=syn.lemmas()\n",
        "           # print(len(lemmas))\n",
        "            qexp.append(x)\n",
        "            for i in range(1,min(3,len(lemmas))):\n",
        "               # print(lemmas[i].name())\n",
        "                qexp.append(lemmas[i].name())\n",
        "        except:\n",
        "           # print(\"Noun!\")\n",
        "            qexp.append(x)\n",
        "\n",
        "    #print(qexp)\n",
        "    queries_exp.append(qexp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGlQBK6WHCvY",
        "colab_type": "code",
        "colab": {},
        "outputId": "0e812a86-e571-4bd3-fe43-1db4ebb58c8b"
      },
      "source": [
        "print(queries[0:5])\n",
        "print(queries_exp[0:5])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['reason', 'behind', 'protest', 'meena', 'leader', 'inclusion', 'gurjars', 'scheduled', 'tribe'], ['attack', 'hezbollah', 'guerrilla', 'indian', 'israeli', 'force'], ['conflict', 'ashok', 'singhal', 'president', 'vishwa', 'hindu', 'parishad', 'lk', 'advani', 'bjp', 'leader', 'ram', 'mandir', 'issue'], ['plan', 'build', 'road', 'china', 'mount', 'everest'], ['initiation', 'legal', 'proceeding', 'advani', 'involvement', 'demolition', 'babri', 'masjid']]\n",
            "[['reason', 'ground', 'behind', 'nates', 'arse', 'protest', 'protestation', 'meena', 'leader', 'inclusion', 'gurjars', 'scheduled', 'tribe', 'folk'], ['attack', 'onslaught', 'onset', 'hezbollah', 'Hezbollah', 'Hizbollah', 'guerrilla', 'guerilla', 'irregular', 'indian', 'American_Indian', 'Red_Indian', 'israeli', 'force'], ['conflict', 'struggle', 'battle', 'ashok', 'singhal', 'president', 'vishwa', 'hindu', 'Hindoo', 'Hindustani', 'parishad', 'lk', 'advani', 'bjp', 'leader', 'ram', 'random_access_memory', 'random_memory', 'mandir', 'issue'], ['plan', 'program', 'programme', 'build', 'build', 'body-build', 'road', 'route', 'china', \"People's_Republic_of_China\", 'mainland_China', 'mount', 'riding_horse', 'mount', 'everest', 'Mount_Everest', 'Mt._Everest'], ['initiation', 'induction', 'installation', 'legal', 'proceeding', 'legal_proceeding', 'proceedings', 'advani', 'involvement', 'participation', 'involvement', 'demolition', 'demolition', 'wipeout', 'babri', 'masjid', 'musjid']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAE8erbXHCvd",
        "colab_type": "code",
        "colab": {},
        "outputId": "ce3e8ebc-51a5-4f37-88e9-2d7deaaa955a"
      },
      "source": [
        "print(len(queries_exp))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7iR6iA1Hqbz",
        "colab_type": "text"
      },
      "source": [
        "Saving all the expanded Queries in csv file, which will be used in later stages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "it61xknAHCvh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "data=[]\n",
        "\n",
        "for i in range(50):\n",
        "    l=[]\n",
        "    l.append(i)\n",
        "    l.append(queries_exp[i]);\n",
        "    data.append(l)\n",
        "    \n",
        "df = pd.DataFrame(data, columns = ['DocId', 'Tokens'])\n",
        "\n",
        "df.to_csv('C:/Users/Subham/IRLab/dataset_query_exp.csv',index=False, header=True)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}