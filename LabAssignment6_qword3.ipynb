{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LabAssignment6_qword3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D84azbgqbfl_",
        "colab_type": "text"
      },
      "source": [
        "**Approach: Query Expansion + Word2Vec + Rochio + gamma= 0.15**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfqB6yLQaUsK",
        "colab_type": "code",
        "outputId": "37be6d67-e44c-4f13-d79a-0704c32e553a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yh4Zuhr-cmgk",
        "colab_type": "text"
      },
      "source": [
        "Reading csv files containing tokens of documents and queries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtvVL_-Kan2-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv('drive/My Drive/dataset.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRwBdj8EatEH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "dfq=pd.read_csv('drive/My Drive/dataset_query_exp.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlxScRo2a0iN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.test.utils import common_texts, get_tmpfile\n",
        "from gensim.models import Word2Vec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIC_je15cqeK",
        "colab_type": "text"
      },
      "source": [
        "Creating list of documents"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLSWbdZ9a4qX",
        "colab_type": "code",
        "outputId": "48b346db-f298-4d40-9485-f4716e98b8de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "sent=[]\n",
        "for i in range(125511):\n",
        "  if(i%10000==0):\n",
        "    print(i)\n",
        "  tokens=df[\"Tokens\"][i][1:len(df[\"Tokens\"][i])-2]\n",
        "  tokens_list=tokens.split(', ')\n",
        "  for i in range(len(tokens_list)):\n",
        "    tokens_list[i]=tokens_list[i][1:len(tokens_list[i])-1]\n",
        "  sent.append(tokens_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "10000\n",
            "20000\n",
            "30000\n",
            "40000\n",
            "50000\n",
            "60000\n",
            "70000\n",
            "80000\n",
            "90000\n",
            "100000\n",
            "110000\n",
            "120000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOfne5K5a9ZA",
        "colab_type": "code",
        "outputId": "6e2a8158-7ca0-4f15-a171-c9685706c7d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(sent))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "125511\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcIkS9_PbIT7",
        "colab_type": "text"
      },
      "source": [
        "**Word embedding using SkipGram Technique**\n",
        "\n",
        "Window size is taken as 2 , Dimension: 100"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59eeUvibbDnK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.test.utils import common_texts, get_tmpfile\n",
        "from gensim.models import Word2Vec\n",
        "model = Word2Vec(sent, size=100, window=2, min_count=1,sg=1) #using skipgram technique"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qStRT1KbSHr",
        "colab_type": "code",
        "outputId": "d2cf10c1-686f-4dcf-aae6-1807ca3d17b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "model.save(\"word2vec.model\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:410: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QO9P_wZvp5_",
        "colab_type": "code",
        "outputId": "4dbd12dc-5e2d-4085-d468-426186a5a299",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "model=Word2Vec.load(\"drive/My Drive/word2vec.model\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:410: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1cJg4Q-uzul",
        "colab_type": "code",
        "outputId": "570ac1fa-6822-423c-d677-29858001188c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model.train(sent,total_examples=125511,epochs=4)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(129914225, 131597408)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CG_R2bypcsbD",
        "colab_type": "text"
      },
      "source": [
        "Creating list of queries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCXAjt0ax0Oi",
        "colab_type": "code",
        "outputId": "fc0198bb-a01a-4585-9254-18bc9fb8e249",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "sent_q=[]\n",
        "for i in range(50):\n",
        "  if(i%5==0):\n",
        "    print(i)\n",
        "  tokens=dfq[\"Tokens\"][i][1:len(dfq[\"Tokens\"][i])-1]\n",
        "  tokens_list=tokens.split(', ')\n",
        "  for i in range(len(tokens_list)):\n",
        "    tokens_list[i]=tokens_list[i][1:len(tokens_list[i])-1]\n",
        "  sent_q.append(tokens_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "5\n",
            "10\n",
            "15\n",
            "20\n",
            "25\n",
            "30\n",
            "35\n",
            "40\n",
            "45\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xqkV4B8x4yT",
        "colab_type": "code",
        "outputId": "0adc093c-c082-470c-e643-da76f747572f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "model.wv[\"reason\"] #Sample word vector of 100 dimensions"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.29024836,  0.1606922 ,  0.52632654, -0.1637964 ,  0.03614322,\n",
              "       -0.49315777, -0.22694942,  0.2694871 ,  0.45510322,  0.24887332,\n",
              "        0.09076   , -0.19231062,  0.21659519, -0.1800657 ,  0.37272257,\n",
              "       -0.30173963,  0.46155885, -0.3380218 , -0.34793428,  0.30021107,\n",
              "        0.13928668, -0.37237358,  0.67735475, -0.41021997, -0.17133668,\n",
              "       -0.7945007 ,  0.29764795, -0.26591083, -0.15248977, -0.35347056,\n",
              "       -0.3059114 , -0.00502704,  0.12856673,  0.06625283, -0.15359287,\n",
              "        0.263658  , -0.2502284 , -0.31511596,  0.1963704 ,  0.3382178 ,\n",
              "        0.44306117,  0.13616435, -0.00379117, -0.18723637, -0.06207887,\n",
              "        0.14326905, -0.5428333 ,  0.58212566, -0.34781802,  0.04669193,\n",
              "       -0.7346095 , -0.31885302, -0.06603304,  0.14635526,  0.04139513,\n",
              "       -0.14362943,  0.2978085 ,  0.15617462,  0.3285208 ,  0.76740634,\n",
              "       -0.05319729, -0.20620589,  0.18436311,  0.21690753,  0.55841845,\n",
              "        0.14592141,  0.25610292,  0.14462425,  0.16700995, -0.2652604 ,\n",
              "        0.09283444,  0.31196496,  0.303552  , -0.60412765, -0.20332827,\n",
              "        0.45624185, -0.3423536 ,  0.06128085,  0.17255792,  0.58486545,\n",
              "       -0.531557  ,  0.04361728, -0.44939795,  0.70769495, -0.09685597,\n",
              "        0.28439078,  0.4404162 , -0.26742133, -0.1429895 , -0.22158512,\n",
              "       -0.49619448,  0.15035225, -0.20117882, -0.02672142,  0.8207162 ,\n",
              "        0.7154171 , -0.12186931, -0.26071757,  0.36823618,  0.44338024],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kttfqlocysl",
        "colab_type": "text"
      },
      "source": [
        "Calculating word2vec embedding (vectors) for each doc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHTxL7Z_x9H9",
        "colab_type": "code",
        "outputId": "a9e93828-b510-4086-82f8-9f6b42d1bdb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "# calculating vectors for each doc\n",
        "\n",
        "import numpy as np\n",
        "doc_rep=np.zeros((125511,100),dtype='float32')\n",
        "for i in range(125511):\n",
        "  docs=sent[i]\n",
        "  no_of_words=len(docs)\n",
        "  word_rep=[]\n",
        "  for x in docs:\n",
        "    word_rep.append(model.wv[x]);\n",
        "  word_rep_arr=np.array(word_rep)\n",
        "  if(i%10000==0):\n",
        "    print(word_rep_arr.shape)\n",
        "    print(i)\n",
        "  doc_rep[i]=np.average(word_rep_arr,axis=0)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(111, 100)\n",
            "0\n",
            "(177, 100)\n",
            "10000\n",
            "(167, 100)\n",
            "20000\n",
            "(178, 100)\n",
            "30000\n",
            "(157, 100)\n",
            "40000\n",
            "(79, 100)\n",
            "50000\n",
            "(280, 100)\n",
            "60000\n",
            "(170, 100)\n",
            "70000\n",
            "(138, 100)\n",
            "80000\n",
            "(303, 100)\n",
            "90000\n",
            "(98, 100)\n",
            "100000\n",
            "(199, 100)\n",
            "110000\n",
            "(411, 100)\n",
            "120000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AAOnfmuyDX2",
        "colab_type": "code",
        "outputId": "1aed73ff-2fdc-4e76-f031-c31097d4e6f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(doc_rep.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(125511, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUDTu91Lc1yF",
        "colab_type": "text"
      },
      "source": [
        "Calculating Word2Vec embedding for each query"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CF9YLtX0yoyH",
        "colab_type": "code",
        "outputId": "0b7bfa62-4516-4f81-d4d1-a97c257bd6a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "source": [
        "# calculating vectors for each query \n",
        "import numpy as np\n",
        "query_rep=np.zeros((50,100),dtype='float32')\n",
        "init=np.zeros((1,100),dtype='float32') # for words not present in trained model\n",
        "p=0;\n",
        "for i in range(50):\n",
        "  #if(i==11 or i==25):\n",
        "   # continue\n",
        "  query=sent_q[i]\n",
        "  no_of_words=len(query)\n",
        "  q_rep=[]\n",
        "  for x in query:\n",
        "    try:\n",
        "      q_rep.append(model.wv[x]);\n",
        "    except:\n",
        "      q_rep.append(init)\n",
        "  q_rep_arr=np.array(q_rep)\n",
        "  print(i)\n",
        "  query_rep[p]=np.average(q_rep_arr,axis=0)\n",
        "  p=p+1\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYlOxex3ywl2",
        "colab_type": "code",
        "outputId": "dd1e198c-52ff-4ab0-a8bf-9854d376b890",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(query_rep.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5EUkFgkc5am",
        "colab_type": "text"
      },
      "source": [
        "Calculating Cosine Similarity Distance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4sbEGEqy1r2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "cos_lib = cosine_similarity(query_rep,doc_rep)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrNHol90zWmK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "df3=pd.read_csv('drive/My Drive/file_names.csv')\n",
        "\n",
        "import pandas as pd\n",
        "df4=pd.read_csv('drive/My Drive/relevant_docs.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awpmW1VjWWGS",
        "colab_type": "text"
      },
      "source": [
        "Note: **Threshold has been taken as 0.83**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdpAaQVUy_zw",
        "colab_type": "code",
        "outputId": "e5307513-18ce-4982-c9f4-78f9f10552e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "dist=[]\n",
        "rel_docs=[] # to store relev\n",
        "actual_rel_docs=[] # actual rel\n",
        "rel_docs_ids=[] # to store indices of rel doc vectors\n",
        "p=0;\n",
        "for k in range(0,50):\n",
        "  dist=[]\n",
        "  a=[] # to store relev\n",
        "  b=[] # actual rel\n",
        "  ai=[] # to store indices of relev\n",
        "  for i in range(len(cos_lib[k])):\n",
        "    dist.append((i,cos_lib[k][i]))\n",
        "\n",
        "  dist=sorted(dist,key=lambda x:x[1],reverse=True)\n",
        "  print(\"Processing...\");\n",
        "  i=0;\n",
        "  while(dist[i][1]>=0.83 and i<125511):\n",
        "   # print(dist[i],\" \",df3[\"File_Name\"][dist[i][0]].split('\\\\')[-1])\n",
        "    a.append(df3[\"File_Name\"][dist[i][0]].split('\\\\')[-1])\n",
        "    ai.append(dist[i][0])\n",
        "    i=i+1;\n",
        "  \n",
        "  print(\"-----------\")\n",
        "  \n",
        "  print(\"Actual Relevant docs: \")\n",
        "  mdf=(df4[df4[\"Id\"]==k+76])\n",
        "  #print(mdf)\n",
        "  #print(len(mdf))\n",
        "  \n",
        "  for i in range(len(mdf)):\n",
        "    b.append(mdf[\"Doc_Name\"][p])\n",
        "    #print(mdf[\"Doc_Name\"][p])\n",
        "    p=p+1;\n",
        "  rel_docs.append(a)\n",
        "  actual_rel_docs.append(b) # actual rel\n",
        "  rel_docs_ids.append(ai)\n",
        "  print(\"------------------------------------\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTYQlTzI5GQL",
        "colab_type": "code",
        "outputId": "694111c5-f2fe-4a09-cd83-74b7faf1d55d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "source": [
        "matches=0\n",
        "for i in range(50):\n",
        "  print(len(actual_rel_docs[i]),\" \",len(set(rel_docs[i]) & set(actual_rel_docs[i])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5   4\n",
            "20   6\n",
            "3   2\n",
            "4   0\n",
            "8   3\n",
            "6   5\n",
            "23   21\n",
            "9   3\n",
            "3   2\n",
            "22   15\n",
            "7   7\n",
            "9   7\n",
            "22   20\n",
            "47   26\n",
            "5   5\n",
            "12   0\n",
            "38   0\n",
            "19   15\n",
            "25   2\n",
            "11   4\n",
            "3   3\n",
            "22   16\n",
            "5   0\n",
            "3   1\n",
            "21   6\n",
            "13   12\n",
            "17   0\n",
            "7   3\n",
            "8   6\n",
            "13   13\n",
            "4   0\n",
            "14   14\n",
            "11   7\n",
            "10   7\n",
            "11   2\n",
            "16   0\n",
            "17   0\n",
            "14   0\n",
            "8   5\n",
            "19   2\n",
            "10   5\n",
            "1   1\n",
            "10   7\n",
            "7   0\n",
            "12   11\n",
            "21   0\n",
            "20   17\n",
            "19   9\n",
            "7   1\n",
            "13   0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kT_VTGLYGXXX",
        "colab_type": "code",
        "outputId": "509981f6-b06a-458a-f274-ab524eda2f54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "matches=0\n",
        "for i in range(50):\n",
        "  matches=matches+len(set(rel_docs[i]) & set(actual_rel_docs[i]))\n",
        "\n",
        "print(\"Total Matches: \",matches)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Matches:  295\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTbmzLgBJwth",
        "colab_type": "code",
        "outputId": "a2f8957c-444e-4e40-ff78-30fa523e7952",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(list(set(rel_docs[0]) & set(actual_rel_docs[0])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['1070603_nation_story_7869357.utf8', '1070602_nation_story_7865940.utf8', '1070611_nation_story_7906812.utf8', '1040901_nation_story_3702283.utf8']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCFgALFpI_fk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "df5=pd.read_csv('drive/My Drive/file_names_new.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wp4IBXgddCg2",
        "colab_type": "text"
      },
      "source": [
        "Storing Relevant and Non-Relevant vectors for each query"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXrS4hypJJlK",
        "colab_type": "code",
        "outputId": "14d51e5c-682f-4066-d0b6-4a8f8c7f3b97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 955
        }
      },
      "source": [
        "dr_rev=np.zeros((50,100),dtype='float32')\n",
        "ndr_rev=np.zeros((50,100),dtype='float32')\n",
        "for i in range(50):\n",
        "  dr=[]\n",
        "  ndr=[]\n",
        "  print(\"processing\")\n",
        "  matched_files=list(set(rel_docs[i]) & set(actual_rel_docs[i]))\n",
        "  for k in range(125511):\n",
        "    if(df5[\"File_Name\"][k] in matched_files):\n",
        "      dr.append(doc_rep[k]) # storing relevant vectors \n",
        "    else:\n",
        "      ndr.append(doc_rep[k]) # storing non relevant vectors\n",
        "  \n",
        "  dr_arr=np.array(dr) # conversion into array\n",
        "  ndr_arr=np.array(ndr)\n",
        "  dr_rev[i]=np.average(dr_arr,axis=0) #finding average of all relevant doc vectors\n",
        "  ndr_rev[i]=np.average(ndr_arr,axis=0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/lib/function_base.py:393: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis)\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vG-YcEdOOmk",
        "colab_type": "code",
        "outputId": "bf682909-f2a7-406d-dd18-d13af0d1765e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "print(dr_rev[4])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-0.30261573 -0.17261827  0.31989288 -0.17712684 -0.10863154 -0.317651\n",
            "  0.11150265  0.17496566  0.06815441  0.07477763  0.09860824  0.29610214\n",
            "  0.1285724  -0.16312607  0.16676687 -0.12959039  0.17175451 -0.41663122\n",
            " -0.14525405 -0.10312333 -0.08668302 -0.18375048  0.46141505  0.3374409\n",
            " -0.18595535 -0.4641924  -0.15313874 -0.10973386  0.11181398 -0.38842502\n",
            " -0.09740677  0.01939033 -0.15007903  0.28319854 -0.05891808  0.3110803\n",
            " -0.421836   -0.3134853   0.16279826  0.17262237  0.37702936 -0.0370237\n",
            " -0.06865855  0.24487019 -0.00902329  0.02460778 -0.12523423  0.30941385\n",
            " -0.2596913   0.15122403 -0.36215204 -0.24956112 -0.06604018 -0.28103238\n",
            "  0.06277902 -0.09090327 -0.00172408 -0.01235844  0.16783574  0.26614302\n",
            " -0.03147031 -0.05432379  0.26207146 -0.06184213  0.27167445 -0.06452016\n",
            "  0.15028414  0.0099738   0.40149826 -0.4491867  -0.09249078 -0.15874343\n",
            " -0.00188263 -0.29630286 -0.03253992  0.39026156 -0.08439225  0.09628262\n",
            "  0.05680417  0.22478385 -0.3041623  -0.06260191 -0.07673559  0.2664124\n",
            " -0.09482454  0.0448867   0.44494683 -0.1628634  -0.1529213  -0.13055632\n",
            " -0.3920252  -0.06774934 -0.15440677  0.04492333  0.445234    0.3597485\n",
            " -0.26890665  0.08806352 -0.01021366 -0.21962328]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpSxnu8MdFTt",
        "colab_type": "text"
      },
      "source": [
        "ROCCHIO Algorithm Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjk6QRWhN7wz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "beta=0.75\n",
        "gamma=0.15\n",
        "mod_q=np.zeros((50,100),dtype='float32')\n",
        "for i in range(50):\n",
        "  if(len(list(set(rel_docs[i]) & set(actual_rel_docs[i])))>0): # checking no. of matches > 0 or not\n",
        "    total_rel=len(list(set(rel_docs[i]) & set(actual_rel_docs[i])));\n",
        "    total_non_rel=125511-total_rel\n",
        "    term=beta/total_rel;\n",
        "    mod_q[i]=np.add(query_rep[i],term*dr_rev[i])\n",
        "    mod_q[i]=np.subtract(mod_q[i],(gamma/total_non_rel)*ndr_rev[i])\n",
        "  else:\n",
        "    mod_q[i]=query_rep[i]\n",
        "    mod_q[i]=np.subtract(mod_q[i],(gamma/total_non_rel)*ndr_rev[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-YucLgTRsb3",
        "colab_type": "code",
        "outputId": "3474bdee-0532-4c1b-9e2e-6eeec90b0375",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "print(query_rep[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-1.38826743e-01 -2.89725542e-01  8.91866311e-02 -1.62501857e-01\n",
            " -1.79269329e-01 -2.09240884e-01  8.73422623e-02  2.11404130e-01\n",
            " -1.28635168e-01  8.95918161e-02 -1.47978514e-01  1.16049066e-01\n",
            "  1.10434815e-01 -1.41472727e-01  1.28401235e-01 -2.02566028e-01\n",
            " -7.58671835e-02 -4.02699381e-01 -1.28056323e-02 -8.33550319e-02\n",
            "  2.91001201e-02  3.56562026e-02  6.01795614e-01  1.06458232e-01\n",
            " -2.87494659e-01 -2.08319739e-01  5.17137870e-02 -2.68226445e-01\n",
            "  1.28063008e-01 -1.86850145e-01 -2.50460416e-01  2.74546780e-02\n",
            " -2.07499298e-03  2.00916484e-01 -1.63578197e-01  3.40943635e-01\n",
            " -3.15326452e-01 -2.97441214e-01  6.55261101e-03  1.70179129e-01\n",
            "  1.70377567e-01 -9.92521569e-02 -5.62905110e-02  1.34052247e-01\n",
            "  1.06473885e-01  4.97432053e-02 -4.99299169e-02  1.11714430e-01\n",
            " -7.33399391e-02  1.38946235e-01 -4.99737918e-01 -2.25056544e-01\n",
            "  2.74080075e-02 -2.45268688e-01  2.34320149e-01 -8.40348676e-02\n",
            "  2.38386691e-02  6.02361560e-02 -4.47600223e-02  3.02614152e-01\n",
            "  1.92013962e-04  1.86042234e-01  3.92119229e-01  2.06890684e-02\n",
            "  1.96812227e-01  5.99469282e-02  1.05314262e-01 -9.71121117e-02\n",
            "  2.70754755e-01 -1.42195225e-01 -5.83578534e-02 -1.78799089e-02\n",
            "  2.96495706e-01 -1.03499889e-01 -5.15999720e-02  2.92598814e-01\n",
            " -4.01593037e-02  4.46177796e-02  1.73163012e-01 -6.70246258e-02\n",
            " -2.43924141e-01 -2.61599630e-01 -2.07033947e-01  1.05837628e-01\n",
            " -6.07281215e-02  2.84973513e-02  3.46884787e-01 -6.07325360e-02\n",
            " -1.45753071e-01 -2.68068433e-01 -1.78128034e-01  5.18603288e-02\n",
            " -1.09935202e-01 -2.25509256e-02  7.50967115e-02  2.88022459e-01\n",
            " -4.35534805e-01  1.24162339e-01 -3.78789082e-02 -1.86585143e-01]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJsfQEC2RvmT",
        "colab_type": "code",
        "outputId": "2a9c8f68-c36b-4821-88d2-e08fb78a97d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "print(mod_q[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-0.17665343 -0.31130266  0.12917289 -0.18464248 -0.19284812 -0.24894682\n",
            "  0.10127994  0.23327468 -0.12011594  0.09893896 -0.13565265  0.15306148\n",
            "  0.12650615 -0.16186327  0.14924689 -0.21876459 -0.05439815 -0.4547777\n",
            " -0.03096219 -0.0962453   0.01826492  0.01268758  0.6594719   0.14863797\n",
            " -0.31073877 -0.2663433   0.03257157 -0.28194308  0.1420396  -0.23540281\n",
            " -0.26263613  0.02987846 -0.02083474  0.23631601 -0.17094295  0.3798283\n",
            " -0.36805546 -0.33662653  0.02690215  0.19175677  0.21750565 -0.10388013\n",
            " -0.0648727   0.16466075  0.1053459   0.05281912 -0.06558415  0.15039077\n",
            " -0.10580108  0.15784915 -0.5450066  -0.25625145  0.01915306 -0.2803974\n",
            "  0.24216746 -0.09539766  0.02362311  0.05869137 -0.02378074  0.33588165\n",
            " -0.00374172  0.17925175  0.42487785  0.01295883  0.23077117  0.05188196\n",
            "  0.12409962 -0.09586544  0.32094163 -0.19834304 -0.06991909 -0.03772268\n",
            "  0.29626036 -0.14053728 -0.0556674   0.34138116 -0.05070818  0.05665297\n",
            "  0.18026355 -0.03892693 -0.28194398 -0.2694248  -0.2166258   0.13913876\n",
            " -0.07258104  0.03410814  0.4025027  -0.08109035 -0.16486807 -0.28438774\n",
            " -0.22713076  0.04339179 -0.12923585 -0.01693555  0.13075052  0.33299065\n",
            " -0.46914783  0.13517019 -0.03915556 -0.21403779]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MakAmpxLT1d3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#finding distance with the modified query\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "cos_lib2 = cosine_similarity(mod_q,doc_rep)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTcQelMwUYpk",
        "colab_type": "code",
        "outputId": "31572996-4160-4254-80e1-f35f5b3cea4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(cos_lib2.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50, 125511)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arcoUo31UEa6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dist2=[]\n",
        "for i in range(len(cos_lib2[0])):\n",
        "  dist2.append((i,cos_lib2[0][i]))\n",
        "\n",
        "dist2=sorted(dist,key=lambda x:x[1],reverse=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbN3oc_lUkxW",
        "colab_type": "code",
        "outputId": "cce23579-2cf5-413b-8017-d1337a1d3048",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "rel_docs2=[] # to store relev\n",
        "p=0;\n",
        "for k in range(0,50):\n",
        "  dist2=[]\n",
        "  a2=[] # to store relev\n",
        "  b2=[] # actual rel\n",
        "  for i in range(len(cos_lib2[k])):\n",
        "    dist2.append((i,cos_lib2[k][i]))\n",
        "\n",
        "  dist2=sorted(dist2,key=lambda x:x[1],reverse=True)\n",
        "  print(\"Processing...\");\n",
        "  i=0;\n",
        "  while(dist2[i][1]>=0.83 and i<125511):\n",
        "   # print(dist[i],\" \",df3[\"File_Name\"][dist[i][0]].split('\\\\')[-1])\n",
        "    a2.append(df3[\"File_Name\"][dist2[i][0]].split('\\\\')[-1])\n",
        "    i=i+1;\n",
        "  \n",
        "  rel_docs2.append(a2)\n",
        "\n",
        "  print(\"------------------------------------\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mV5Mq-BqV0Cx",
        "colab_type": "code",
        "outputId": "88689d09-c29c-4bb1-feee-3886e0918f98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "matches=0\n",
        "for i in range(50):\n",
        "  matches=matches+len(set(rel_docs2[i]) & set(actual_rel_docs[i]))\n",
        "\n",
        "print(\"Total Matches: \",matches)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Matches:  381\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7NIirExWBdm",
        "colab_type": "text"
      },
      "source": [
        "As we can see, no. of matches increased from 295 to 381 after implementing Rocchio Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9f-7AoWYRxb",
        "colab_type": "code",
        "outputId": "d494becf-4b9e-4ca1-b7da-f70f07f2120b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(\"Average Precison: \", matches/125511)\n",
        "print(\"Average Recall: \", matches/653)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average Precison:  0.0030355905060114254\n",
            "Average Recall:  0.5834609494640123\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}