{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LabAssignment6_qtr2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bjobf-F10bpM",
        "colab_type": "text"
      },
      "source": [
        "**Approach:**\n",
        "\n",
        "1.   Query Expansion + TF-IDF + Rocchio + Gamma =0.15\n",
        "2.   Query Expansion + TF-IDF + Rocchio + Gamma =0\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2lewXK8tVZn",
        "colab_type": "code",
        "outputId": "ce407e7e-8872-46a8-867a-9de472fdfab8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCzX5QZcFgRP",
        "colab_type": "text"
      },
      "source": [
        "Reading csv files which contain pre-processed tokens from Documents and Expanded Queries respectively. Expanded Queries has been previously calculated and stored in dataset_query_exp.csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gjy2Y1qNtihx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv('drive/My Drive/dataset.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oI5k1uKAtj3G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "dfq=pd.read_csv('drive/My Drive/dataset_query_exp.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3eSQcGUFtbz",
        "colab_type": "text"
      },
      "source": [
        "Creating List of Document tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDIEqAeutmWL",
        "colab_type": "code",
        "outputId": "f072e5f2-9e37-483d-a5ea-141d8abc94b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "sent=[]\n",
        "for i in range(125511):\n",
        "  if(i%10000==0):\n",
        "    print(i)\n",
        "  tokens=df[\"Tokens\"][i][1:len(df[\"Tokens\"][i])-2]\n",
        "  tokens_list=tokens.split(', ')\n",
        "  for i in range(len(tokens_list)):\n",
        "    tokens_list[i]=tokens_list[i][1:len(tokens_list[i])-1]\n",
        "  sent.append(tokens_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "10000\n",
            "20000\n",
            "30000\n",
            "40000\n",
            "50000\n",
            "60000\n",
            "70000\n",
            "80000\n",
            "90000\n",
            "100000\n",
            "110000\n",
            "120000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Le64ZkawFyEP",
        "colab_type": "text"
      },
      "source": [
        "Create list of Document sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGGX2q4Uto1i",
        "colab_type": "code",
        "outputId": "25a3676f-965f-4f42-f637-d80b99f5d495",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "docs2=[]\n",
        "docs=sent\n",
        "for st in docs:\n",
        "    st=' '.join(st);\n",
        "    docs2.append(st);\n",
        "docs=docs2;\n",
        "docs2=[]\n",
        "print(docs[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "telegraph calcutta leisure tuesday december 07 2004 leonardo dicaprio one moment didnt know whether laugh cry south american rainforest studying effect mercury poisoning amazon confronted group naked ind six oscar big profit chicago sparked new frenzy filming musical andrew lloyd webbers couple live together britain without getting married warned today risk losing home po may come crunch squelch creator hoping splash french fashion legend pierre cardin putting much empire sale seeking 1 billion couture licens family astonishingly even today many parent believe bringing daughter security gilded cage insulated first cousin 27 year old want get married parent particularly interested friend mine actor diane kruger uk premiere film national treasure london reuter\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXoj9wyEGEAr",
        "colab_type": "text"
      },
      "source": [
        "Create list of Query Tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TOLNctqtqfO",
        "colab_type": "code",
        "outputId": "c158370d-710f-46d3-d971-4196f8937803",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "sent_q=[]\n",
        "for i in range(50):\n",
        "  if(i%5==0):\n",
        "    print(i)\n",
        "  tokens=dfq[\"Tokens\"][i][1:len(dfq[\"Tokens\"][i])-1]\n",
        "  tokens_list=tokens.split(', ')\n",
        "  for i in range(len(tokens_list)):\n",
        "    tokens_list[i]=tokens_list[i][1:len(tokens_list[i])-1]\n",
        "  sent_q.append(tokens_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "5\n",
            "10\n",
            "15\n",
            "20\n",
            "25\n",
            "30\n",
            "35\n",
            "40\n",
            "45\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Rn00Lx8GINK",
        "colab_type": "text"
      },
      "source": [
        "Create list of Query sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YK5n9TG_tsHj",
        "colab_type": "code",
        "outputId": "5900c913-6a5f-457b-e8d8-c85dc97b1d01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "docs2_q=[]\n",
        "docs_q=sent_q\n",
        "for st in docs_q:\n",
        "    st=' '.join(st);\n",
        "    docs2_q.append(st);\n",
        "docs_q=docs2_q;\n",
        "docs2_q=[]\n",
        "print(docs_q[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "reason ground behind nates arse protest protestation meena leader inclusion gurjars scheduled tribe folk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86ANOOxGGQDy",
        "colab_type": "text"
      },
      "source": [
        "finding tf-idf vectorizer for docs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpYY_s2ztt3D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# finding tf-idf vectorizer for docs\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(docs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUE7P-tiGTXi",
        "colab_type": "text"
      },
      "source": [
        "finding tf-idf vectorizer for queries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKAtDyEmtvnr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# finding tf-idf vectorizer for queries\n",
        "Y = vectorizer.transform(docs_q)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2YOD2lixRDf",
        "colab_type": "code",
        "outputId": "218c5bf7-2447-4de6-f12f-3a13fd5b45da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(X.shape)\n",
        "print(Y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(125511, 376999)\n",
            "(50, 376999)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tk4v2-ktzIJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list_q=[]\n",
        "for i in range(50):\n",
        "  a=Y[i].toarray()\n",
        "  l=list(a[0])\n",
        "  list_q.append(l)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpeqlkTht0oZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "array_q=np.array(list_q,dtype='float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61_nhMCet4Mg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cos_lib=np.zeros(shape=(125511,50)) # to store distances"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-v1vi_DGXTW",
        "colab_type": "text"
      },
      "source": [
        "Finding Cosine Similarity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuAHSKJnt7S8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "cos_lib = cosine_similarity(Y,X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4w2LfqAGasK",
        "colab_type": "text"
      },
      "source": [
        "Reading csv files containing File Names and Relevant Doc names for each query"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_Yp1KbGt-6H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "df3=pd.read_csv('drive/My Drive/file_names.csv')\n",
        "\n",
        "import pandas as pd\n",
        "df4=pd.read_csv('drive/My Drive/relevant_docs.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3brkGW-fGfFj",
        "colab_type": "text"
      },
      "source": [
        "Threshold taken as **0.15**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Cikz_N1u57j",
        "colab_type": "code",
        "outputId": "91ea7821-0056-42e9-e182-b94cdff73546",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "dist=[]\n",
        "rel_docs=[] # to store relev\n",
        "actual_rel_docs=[] # actual rel\n",
        "rel_docs_ids=[] # to store indices of rel doc vectors\n",
        "p=0;\n",
        "for k in range(0,50):\n",
        "  dist=[]\n",
        "  a=[] # to store relev\n",
        "  b=[] # actual rel\n",
        "  ai=[] # to store indices of relev\n",
        "  for i in range(len(cos_lib[k])):\n",
        "    dist.append((i,cos_lib[k][i]))\n",
        "\n",
        "  dist=sorted(dist,key=lambda x:x[1],reverse=True)\n",
        "  print(\"Processing...\");\n",
        "  i=0;\n",
        "  while(dist[i][1]>=0.15 and i<125511):\n",
        "   # print(dist[i],\" \",df3[\"File_Name\"][dist[i][0]].split('\\\\')[-1])\n",
        "    a.append(df3[\"File_Name\"][dist[i][0]].split('\\\\')[-1])\n",
        "    ai.append(dist[i][0])\n",
        "    i=i+1;\n",
        "  \n",
        "  print(\"-----------\")\n",
        "  \n",
        "  print(\"Actual Relevant docs: \")\n",
        "  mdf=(df4[df4[\"Id\"]==k+76])\n",
        "  #print(mdf)\n",
        "  #print(len(mdf))\n",
        "  \n",
        "  for i in range(len(mdf)):\n",
        "    b.append(mdf[\"Doc_Name\"][p])\n",
        "    #print(mdf[\"Doc_Name\"][p])\n",
        "    p=p+1;\n",
        "  rel_docs.append(a)\n",
        "  actual_rel_docs.append(b) # actual rel\n",
        "  rel_docs_ids.append(ai)\n",
        "  print(\"------------------------------------\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMURc1VYu8LA",
        "colab_type": "code",
        "outputId": "53d28a83-9ff1-428b-aab1-4747d5973256",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "source": [
        "matches=0\n",
        "for i in range(50):\n",
        "  print(len(actual_rel_docs[i]),\" \",len(set(rel_docs[i]) & set(actual_rel_docs[i])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5   0\n",
            "20   0\n",
            "3   2\n",
            "4   0\n",
            "8   2\n",
            "6   0\n",
            "23   0\n",
            "9   2\n",
            "3   0\n",
            "22   2\n",
            "7   2\n",
            "9   2\n",
            "22   11\n",
            "47   5\n",
            "5   1\n",
            "12   1\n",
            "38   0\n",
            "19   0\n",
            "25   1\n",
            "11   0\n",
            "3   0\n",
            "22   14\n",
            "5   0\n",
            "3   0\n",
            "21   4\n",
            "13   3\n",
            "17   3\n",
            "7   0\n",
            "8   0\n",
            "13   1\n",
            "4   0\n",
            "14   0\n",
            "11   1\n",
            "10   0\n",
            "11   2\n",
            "16   0\n",
            "17   0\n",
            "14   0\n",
            "8   0\n",
            "19   0\n",
            "10   0\n",
            "1   0\n",
            "10   0\n",
            "7   0\n",
            "12   0\n",
            "21   1\n",
            "20   1\n",
            "19   16\n",
            "7   0\n",
            "13   0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aAKlYZpu-rD",
        "colab_type": "code",
        "outputId": "504f01d7-6957-4525-e066-822406d1363c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "matches=0\n",
        "for i in range(50):\n",
        "  matches=matches+len(set(rel_docs[i]) & set(actual_rel_docs[i]))\n",
        "\n",
        "print(\"Total Matches: \",matches)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Matches:  77\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8KV_p6Bw1De",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "temp=np.zeros((1,376999),dtype='float32')\n",
        "for k in range(125511):\n",
        "    temp=np.add(temp,(X[k].toarray())) # storing relevant vectors "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gln4-P0YyY0c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "df5=pd.read_csv('drive/My Drive/file_names_new.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbgVpDurGkb-",
        "colab_type": "text"
      },
      "source": [
        "Calculating Relevant Docs and Non Relevant Docs vectors for each query"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vNd-D3XvA1X",
        "colab_type": "code",
        "outputId": "1b9e0991-83a7-4cc0-d152-2c86ba31b9c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "source": [
        "import numpy as np\n",
        "dr_rev=np.zeros((50,376999),dtype='float32')\n",
        "ndr_rev=np.zeros((50,376999),dtype='float32')\n",
        "\n",
        "for i in range(50):\n",
        "\n",
        "  tempnr=np.zeros((1,376999),dtype='float32')\n",
        "  tempr=np.zeros((1,376999),dtype='float32')\n",
        "  \n",
        "  \n",
        "  matched_files=list(set(rel_docs[i]) & set(actual_rel_docs[i]))\n",
        "  mat=len(matched_files)\n",
        "  nmat=125511-mat\n",
        "  print(\"Processing...\")\n",
        "  for k in range(125511):\n",
        "    if(df5[\"File_Name\"][k] in matched_files):\n",
        "      tempr=np.add(tempr,(X[k].toarray())) # storing relevant vectors \n",
        "      mat=mat+1;\n",
        "  \n",
        "  tempnr=np.subtract(temp,tempr)\n",
        "\n",
        "  if(mat!=0):\n",
        "    dr_rev[i]=tempr/mat #finding average of all relevant doc vectors\n",
        "  if(nmat!=0):\n",
        "    ndr_rev[i]=tempnr/nmat;"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEZsMbrYGn9P",
        "colab_type": "text"
      },
      "source": [
        "ROCCHIO Algorithm Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ip34Xs-jyhm6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "beta=0.75\n",
        "gamma=0.15\n",
        "mod_q=np.zeros((50,376999),dtype='float32')\n",
        "for i in range(50):\n",
        "  if(len(list(set(rel_docs[i]) & set(actual_rel_docs[i])))>0): # checking no. of matches > 0 or not\n",
        "    total_rel=len(list(set(rel_docs[i]) & set(actual_rel_docs[i])));\n",
        "    total_non_rel=125511-total_rel\n",
        "    term=beta/total_rel;\n",
        "    mod_q[i]=np.add(array_q[i],term*dr_rev[i])\n",
        "    mod_q[i]=np.subtract(mod_q[i],(gamma/total_non_rel)*ndr_rev[i])\n",
        "  else:\n",
        "    total_non_rel=125511\n",
        "    mod_q[i]=array_q[i]\n",
        "    mod_q[i]=np.subtract(mod_q[i],(gamma/total_non_rel)*ndr_rev[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0o-kQVtGqll",
        "colab_type": "text"
      },
      "source": [
        "finding cosine Similarity with the modified query"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_hqilQHzTkk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#finding relevant with the modified query\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "cos_lib2 = cosine_similarity(mod_q,X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrfj_nHlzfiG",
        "colab_type": "code",
        "outputId": "ec503036-315f-4665-abb1-dca3a83a7af9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "rel_docs2=[] # to store relev\n",
        "p=0;\n",
        "for k in range(0,50):\n",
        "  dist2=[]\n",
        "  a2=[] # to store relev\n",
        "  b2=[] # actual rel\n",
        "  for i in range(len(cos_lib2[k])):\n",
        "    dist2.append((i,cos_lib2[k][i]))\n",
        "\n",
        "  dist2=sorted(dist2,key=lambda x:x[1],reverse=True)\n",
        "  print(\"Processing...\");\n",
        "  i=0;\n",
        "  while(dist2[i][1]>=0.15 and i<125511):\n",
        "   # print(dist[i],\" \",df3[\"File_Name\"][dist[i][0]].split('\\\\')[-1])\n",
        "    a2.append(df3[\"File_Name\"][dist2[i][0]].split('\\\\')[-1])\n",
        "    i=i+1;\n",
        "  \n",
        "  rel_docs2.append(a2)\n",
        "\n",
        "  print(\"------------------------------------\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u38Sljuvzqw5",
        "colab_type": "code",
        "outputId": "1d0e01a7-ad2a-43e7-f4fe-7252dabf017f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "matches=0\n",
        "for i in range(50):\n",
        "  matches=matches+len(set(rel_docs2[i]) & set(actual_rel_docs[i]))\n",
        "\n",
        "print(\"Total Matches: \",matches)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Matches:  86\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOJDCu3AzvYR",
        "colab_type": "text"
      },
      "source": [
        "As we can see, no. of matches increased from 77 to 86\n",
        "after implementing Rocchio Algorithm\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECpw-dlLz3J8",
        "colab_type": "code",
        "outputId": "1f55deae-4522-4e06-bb5d-74266af8fd65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(\"Average Precison: \", matches/125511)\n",
        "print(\"Average Recall: \", matches/653)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average Precison:  0.0006851989068687207\n",
            "Average Recall:  0.13169984686064318\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uykTVikhz7Ux",
        "colab_type": "text"
      },
      "source": [
        "Now for **Gamma=0**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPF9HmpOz-l6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "beta=0.75\n",
        "gamma=0\n",
        "mod_q=np.zeros((50,376999),dtype='float32')\n",
        "for i in range(50):\n",
        "  if(len(list(set(rel_docs[i]) & set(actual_rel_docs[i])))>0): # checking no. of matches > 0 or not\n",
        "    total_rel=len(list(set(rel_docs[i]) & set(actual_rel_docs[i])));\n",
        "    total_non_rel=125511-total_rel\n",
        "    term=beta/total_rel;\n",
        "    mod_q[i]=np.add(array_q[i],term*dr_rev[i])\n",
        "    mod_q[i]=np.subtract(mod_q[i],(gamma/total_non_rel)*ndr_rev[i])\n",
        "  else:\n",
        "    total_non_rel=125511\n",
        "    mod_q[i]=array_q[i]\n",
        "    mod_q[i]=np.subtract(mod_q[i],(gamma/total_non_rel)*ndr_rev[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TydRvgcm0FL9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#finding relevant with the modified query\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "cos_lib2 = cosine_similarity(mod_q,X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIQTWl-E0IKR",
        "colab_type": "code",
        "outputId": "88396975-45bc-4de8-9783-fa8c3521f4b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "rel_docs2=[] # to store relev\n",
        "p=0;\n",
        "for k in range(0,50):\n",
        "  dist2=[]\n",
        "  a2=[] # to store relev\n",
        "  b2=[] # actual rel\n",
        "  for i in range(len(cos_lib2[k])):\n",
        "    dist2.append((i,cos_lib2[k][i]))\n",
        "\n",
        "  dist2=sorted(dist2,key=lambda x:x[1],reverse=True)\n",
        "  print(\"Processing...\");\n",
        "  i=0;\n",
        "  while(dist2[i][1]>=0.15 and i<125511):\n",
        "   # print(dist[i],\" \",df3[\"File_Name\"][dist[i][0]].split('\\\\')[-1])\n",
        "    a2.append(df3[\"File_Name\"][dist2[i][0]].split('\\\\')[-1])\n",
        "    i=i+1;\n",
        "  \n",
        "  rel_docs2.append(a2)\n",
        "\n",
        "  print(\"------------------------------------\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vj4sXrxm0Mpr",
        "colab_type": "code",
        "outputId": "81a4d973-0edf-4419-f12d-da22d6930b33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "matches=0\n",
        "for i in range(50):\n",
        "  matches=matches+len(set(rel_docs2[i]) & set(actual_rel_docs[i]))\n",
        "\n",
        "print(\"Total Matches: \",matches)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Matches:  86\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDC1Gz0N0P05",
        "colab_type": "code",
        "outputId": "b1d5162a-935b-461c-8f66-713c8ae4214c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(\"Average Precison: \", matches/125511)\n",
        "print(\"Average Recall: \", matches/653)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average Precison:  0.0006851989068687207\n",
            "Average Recall:  0.13169984686064318\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvAjg4NH0Rh5",
        "colab_type": "text"
      },
      "source": [
        "We observe that no. of matches do not increase after\n",
        "changing gamma to 0"
      ]
    }
  ]
}