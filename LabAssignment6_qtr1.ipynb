{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LabAssignment6_qtr1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBwSBRI18QK5",
        "colab_type": "text"
      },
      "source": [
        "**Approach :**\n",
        "1.   Query + TF-IDF + Rocchio + Gamma =0.15\n",
        "2.   Query + TF-IDF + Rocchio + Gamma =0\n",
        "\n",
        "\n",
        "           "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1nNOb3W7LcN",
        "colab_type": "code",
        "outputId": "e8221a4b-4496-4576-968a-cf511b9448b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hn6Dcr9CDlp-",
        "colab_type": "text"
      },
      "source": [
        "Reading csv files which contain pre-processed tokens from Documents and Queries respectively"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4dFkAu0_y2G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv('drive/My Drive/dataset.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQ-ucQBLAOTc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "dfq=pd.read_csv('drive/My Drive/dataset_query.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjd6jWZCDtsl",
        "colab_type": "text"
      },
      "source": [
        "Creating List of Document tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_L6R-v9A16W",
        "colab_type": "code",
        "outputId": "258273bb-7dd3-4b21-ae67-c13619b6ea4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "sent=[]\n",
        "for i in range(125511):\n",
        "  if(i%10000==0):\n",
        "    print(i)\n",
        "  tokens=df[\"Tokens\"][i][1:len(df[\"Tokens\"][i])-2]\n",
        "  tokens_list=tokens.split(', ')\n",
        "  for i in range(len(tokens_list)):\n",
        "    tokens_list[i]=tokens_list[i][1:len(tokens_list[i])-1]\n",
        "  sent.append(tokens_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "10000\n",
            "20000\n",
            "30000\n",
            "40000\n",
            "50000\n",
            "60000\n",
            "70000\n",
            "80000\n",
            "90000\n",
            "100000\n",
            "110000\n",
            "120000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sidedCdA9vM",
        "colab_type": "code",
        "outputId": "e2aefbc9-1b15-4d58-dbd3-0667445f8f20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(sent))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "125511\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zO-0mpRkBBGK",
        "colab_type": "code",
        "outputId": "ae635578-7e5e-41f3-a7c9-6196042b175a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(sent[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['telegraph', 'calcutta', 'leisure', 'tuesday', 'december', '07', '2004', 'leonardo', 'dicaprio', 'one', 'moment', 'didnt', 'know', 'whether', 'laugh', 'cry', 'south', 'american', 'rainforest', 'studying', 'effect', 'mercury', 'poisoning', 'amazon', 'confronted', 'group', 'naked', 'ind', 'six', 'oscar', 'big', 'profit', 'chicago', 'sparked', 'new', 'frenzy', 'filming', 'musical', 'andrew', 'lloyd', 'webbers', 'couple', 'live', 'together', 'britain', 'without', 'getting', 'married', 'warned', 'today', 'risk', 'losing', 'home', 'po', 'may', 'come', 'crunch', 'squelch', 'creator', 'hoping', 'splash', 'french', 'fashion', 'legend', 'pierre', 'cardin', 'putting', 'much', 'empire', 'sale', 'seeking', '1', 'billion', 'couture', 'licens', 'family', 'astonishingly', 'even', 'today', 'many', 'parent', 'believe', 'bringing', 'daughter', 'security', 'gilded', 'cage', 'insulated', 'first', 'cousin', '27', 'year', 'old', 'want', 'get', 'married', 'parent', 'particularly', 'interested', 'friend', 'mine', 'actor', 'diane', 'kruger', 'uk', 'premiere', 'film', 'national', 'treasure', 'london', 'reuter']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdvReqGoF_Hv",
        "colab_type": "text"
      },
      "source": [
        "Create list of Document sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrEI4_M8IMT7",
        "colab_type": "code",
        "outputId": "b4414868-6370-45ae-962a-dfc64643f170",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "docs2=[]\n",
        "docs=sent\n",
        "for st in docs:\n",
        "    st=' '.join(st);\n",
        "    docs2.append(st);\n",
        "docs=docs2;\n",
        "docs2=[]\n",
        "print(docs[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "telegraph calcutta leisure tuesday december 07 2004 leonardo dicaprio one moment didnt know whether laugh cry south american rainforest studying effect mercury poisoning amazon confronted group naked ind six oscar big profit chicago sparked new frenzy filming musical andrew lloyd webbers couple live together britain without getting married warned today risk losing home po may come crunch squelch creator hoping splash french fashion legend pierre cardin putting much empire sale seeking 1 billion couture licens family astonishingly even today many parent believe bringing daughter security gilded cage insulated first cousin 27 year old want get married parent particularly interested friend mine actor diane kruger uk premiere film national treasure london reuter\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMdwyMFLDzmt",
        "colab_type": "text"
      },
      "source": [
        "Create list of Query Tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upwVWovKBI1s",
        "colab_type": "code",
        "outputId": "ada5ca67-1cf6-48da-d997-c7b1d5706915",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "sent_q=[]\n",
        "for i in range(50):\n",
        "  if(i%5==0):\n",
        "    print(i)\n",
        "  tokens=dfq[\"Tokens\"][i][1:len(dfq[\"Tokens\"][i])-1]\n",
        "  tokens_list=tokens.split(', ')\n",
        "  for i in range(len(tokens_list)):\n",
        "    tokens_list[i]=tokens_list[i][1:len(tokens_list[i])-1]\n",
        "  sent_q.append(tokens_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "5\n",
            "10\n",
            "15\n",
            "20\n",
            "25\n",
            "30\n",
            "35\n",
            "40\n",
            "45\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnG6QQasBLYN",
        "colab_type": "code",
        "outputId": "ebab8ef1-4d89-42ca-9b92-74987ed66425",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(sent_q[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['reason', 'behind', 'protest', 'meena', 'leader', 'inclusion', 'gurjars', 'scheduled', 'tribe']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvmbRZGdD6-h",
        "colab_type": "text"
      },
      "source": [
        "Creating List of Query Sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umPgscw-dyaH",
        "colab_type": "code",
        "outputId": "aee86a00-a51b-4fd2-a192-440781aeb403",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "docs2_q=[]\n",
        "docs_q=sent_q\n",
        "for st in docs_q:\n",
        "    st=' '.join(st);\n",
        "    docs2_q.append(st);\n",
        "docs_q=docs2_q;\n",
        "docs2_q=[]\n",
        "print(docs_q[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "reason behind protest meena leader inclusion gurjars scheduled tribe\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8AHtVDdEBL4",
        "colab_type": "text"
      },
      "source": [
        "finding tf-idf vectorizer for docs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "en353wh1EZm8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(docs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZX-uh_PQuGD",
        "colab_type": "code",
        "outputId": "7774f6aa-62f6-41af-fe13-b338f993455d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(X.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(125511, 376999)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71WX-zD2EEyf",
        "colab_type": "text"
      },
      "source": [
        "finding tf-idf vectorizer for queries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQhFf-jbd-Ts",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y = vectorizer.transform(docs_q)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvBA-vspeHMo",
        "colab_type": "code",
        "outputId": "8093cc0e-b291-48d2-e0ec-d81bb4d13a41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(Y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50, 376999)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dju6a5r-VJw-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list_q=[]\n",
        "for i in range(50):\n",
        "  a=Y[i].toarray()\n",
        "  l=list(a[0])\n",
        "  list_q.append(l)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRwjVJihVO-e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "array_q=np.array(list_q,dtype='float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XtU1qDwFAMo",
        "colab_type": "code",
        "outputId": "96c9ec3b-f35d-4795-9b16-95e1c9534160",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(array_q.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50, 376999)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKbXkMaPKMT2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cos_lib=np.zeros(shape=(125511,50)) # to store distances"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FTk7NpeEO9q",
        "colab_type": "text"
      },
      "source": [
        "Finding Cosine Similarity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejULrJvQHu8O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "cos_lib = cosine_similarity(Y,X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTz1Y70YL8WG",
        "colab_type": "code",
        "outputId": "231d3ec2-075c-4640-e24f-dd477576230b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(cos_lib[0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "125511\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1NHNnwxMZWy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(sorted(cos_lib[0],reverse=True))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVJaCNbBYTcS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dist=[]\n",
        "for i in range(len(cos_lib[0])):\n",
        "  dist.append((i,cos_lib[0][i]))\n",
        "\n",
        "dist=sorted(dist,key=lambda x:x[1],reverse=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcBVsp0hMJNG",
        "colab_type": "code",
        "outputId": "6d71a46b-a197-4870-a34d-c3f2c933f358",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(dist[0:5])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(53871, 0.42057022480782225), (124171, 0.4137515041348493), (121321, 0.37781501957210617), (121571, 0.35941066924297405), (66898, 0.336506653547955)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYG3fEHEEVfB",
        "colab_type": "text"
      },
      "source": [
        "Reading csv files containing File Names and Relevant Doc names for each query"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZ5mWVzPNFUF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "df3=pd.read_csv('drive/My Drive/file_names.csv')\n",
        "\n",
        "import pandas as pd\n",
        "df4=pd.read_csv('drive/My Drive/relevant_docs.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hw32Mw-aEaPa",
        "colab_type": "text"
      },
      "source": [
        "Threshold taken as **0.15**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8C1tRlmM6YJ",
        "colab_type": "code",
        "outputId": "24c81715-9f87-451c-b361-9c02525869bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "dist=[]\n",
        "rel_docs=[] # to store relev\n",
        "actual_rel_docs=[] # actual rel\n",
        "rel_docs_ids=[] # to store indices of rel doc vectors\n",
        "p=0;\n",
        "for k in range(0,50):\n",
        "  dist=[]\n",
        "  a=[] # to store relev\n",
        "  b=[] # actual rel\n",
        "  ai=[] # to store indices of relev\n",
        "  for i in range(len(cos_lib[k])):\n",
        "    dist.append((i,cos_lib[k][i]))\n",
        "\n",
        "  dist=sorted(dist,key=lambda x:x[1],reverse=True)\n",
        "  print(\"Processing...\");\n",
        "  i=0;\n",
        "  while(dist[i][1]>=0.15 and i<125511):\n",
        "   # print(dist[i],\" \",df3[\"File_Name\"][dist[i][0]].split('\\\\')[-1])\n",
        "    a.append(df3[\"File_Name\"][dist[i][0]].split('\\\\')[-1])\n",
        "    ai.append(dist[i][0])\n",
        "    i=i+1;\n",
        "  \n",
        "  print(\"-----------\")\n",
        "  \n",
        "  print(\"Actual Relevant docs: \")\n",
        "  mdf=(df4[df4[\"Id\"]==k+76])\n",
        "  #print(mdf)\n",
        "  #print(len(mdf))\n",
        "  \n",
        "  for i in range(len(mdf)):\n",
        "    b.append(mdf[\"Doc_Name\"][p])\n",
        "    #print(mdf[\"Doc_Name\"][p])\n",
        "    p=p+1;\n",
        "  rel_docs.append(a)\n",
        "  actual_rel_docs.append(b) # actual rel\n",
        "  rel_docs_ids.append(ai)\n",
        "  print(\"------------------------------------\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpzLQksKNA3u",
        "colab_type": "code",
        "outputId": "717cdd95-ff9a-4cfb-e8b3-2a3594a9921a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "source": [
        "matches=0\n",
        "for i in range(50):\n",
        "  print(len(actual_rel_docs[i]),\" \",len(set(rel_docs[i]) & set(actual_rel_docs[i])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5   0\n",
            "20   1\n",
            "3   2\n",
            "4   0\n",
            "8   3\n",
            "6   0\n",
            "23   1\n",
            "9   2\n",
            "3   0\n",
            "22   2\n",
            "7   4\n",
            "9   2\n",
            "22   13\n",
            "47   7\n",
            "5   3\n",
            "12   1\n",
            "38   2\n",
            "19   0\n",
            "25   1\n",
            "11   0\n",
            "3   2\n",
            "22   14\n",
            "5   0\n",
            "3   0\n",
            "21   4\n",
            "13   3\n",
            "17   3\n",
            "7   0\n",
            "8   0\n",
            "13   1\n",
            "4   0\n",
            "14   0\n",
            "11   1\n",
            "10   0\n",
            "11   1\n",
            "16   0\n",
            "17   0\n",
            "14   0\n",
            "8   0\n",
            "19   1\n",
            "10   0\n",
            "1   0\n",
            "10   2\n",
            "7   0\n",
            "12   0\n",
            "21   2\n",
            "20   1\n",
            "19   18\n",
            "7   0\n",
            "13   0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWb7IodUOtsf",
        "colab_type": "code",
        "outputId": "add917f8-a01b-4682-9854-3b0fe60bda2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "matches=0\n",
        "for i in range(50):\n",
        "  matches=matches+len(set(rel_docs[i]) & set(actual_rel_docs[i]))\n",
        "\n",
        "print(\"Total Matches: \",matches)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Matches:  97\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-1owqa04E97",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "temp=np.zeros((1,376999),dtype='float32')\n",
        "for k in range(125511):\n",
        "    temp=np.add(temp,(X[k].toarray())) # storing relevant vectors "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsNklTa7N3vd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "df5=pd.read_csv('drive/My Drive/file_names_new.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIlap0WAEhKZ",
        "colab_type": "text"
      },
      "source": [
        "Calculating Relevant Docs and Non Relevant Docs vectors for each query"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFREWC5zN58k",
        "colab_type": "code",
        "outputId": "ad4242cb-7f9b-4739-d53c-ee85f17df6be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "source": [
        "import numpy as np\n",
        "dr_rev=np.zeros((50,376999),dtype='float32')\n",
        "ndr_rev=np.zeros((50,376999),dtype='float32')\n",
        "\n",
        "for i in range(50):\n",
        "\n",
        "  tempnr=np.zeros((1,376999),dtype='float32')\n",
        "  tempr=np.zeros((1,376999),dtype='float32')\n",
        "  \n",
        "  \n",
        "  matched_files=list(set(rel_docs[i]) & set(actual_rel_docs[i]))\n",
        "  mat=len(matched_files)\n",
        "  nmat=125511-mat\n",
        "  print(\"Processing...\")\n",
        "  for k in range(125511):\n",
        "    if(df5[\"File_Name\"][k] in matched_files):\n",
        "      tempr=np.add(tempr,(X[k].toarray())) # storing relevant vectors \n",
        "      mat=mat+1;\n",
        "  \n",
        "  tempnr=np.subtract(temp,tempr)\n",
        "\n",
        "  if(mat!=0):\n",
        "    dr_rev[i]=tempr/mat #finding average of all relevant doc vectors\n",
        "  if(nmat!=0):\n",
        "    ndr_rev[i]=tempnr/nmat;"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n",
            "Processing...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bEd9eEtEpvZ",
        "colab_type": "text"
      },
      "source": [
        "ROCCHIO Algorithm Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04yNkHafXqaz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "beta=0.75\n",
        "gamma=0.15\n",
        "mod_q=np.zeros((50,376999),dtype='float32')\n",
        "for i in range(50):\n",
        "  if(len(list(set(rel_docs[i]) & set(actual_rel_docs[i])))>0): # checking no. of matches > 0 or not\n",
        "    total_rel=len(list(set(rel_docs[i]) & set(actual_rel_docs[i])));\n",
        "    total_non_rel=125511-total_rel\n",
        "    term=beta/total_rel;\n",
        "    mod_q[i]=np.add(array_q[i],term*dr_rev[i])\n",
        "    mod_q[i]=np.subtract(mod_q[i],(gamma/total_non_rel)*ndr_rev[i])\n",
        "  else:\n",
        "    total_non_rel=125511\n",
        "    mod_q[i]=array_q[i]\n",
        "    mod_q[i]=np.subtract(mod_q[i],(gamma/total_non_rel)*ndr_rev[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdkEZBRAEuUQ",
        "colab_type": "text"
      },
      "source": [
        "finding cosine Similarity with the modified query"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRoBYqU_Pn5H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "cos_lib2 = cosine_similarity(mod_q,X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQCRMZOq4iP9",
        "colab_type": "code",
        "outputId": "5fbdf99d-17ec-48a9-d2cf-5945e09a25f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "rel_docs2=[] # to store relev\n",
        "p=0;\n",
        "for k in range(0,50):\n",
        "  dist2=[]\n",
        "  a2=[] # to store relev\n",
        "  b2=[] # actual rel\n",
        "  for i in range(len(cos_lib2[k])):\n",
        "    dist2.append((i,cos_lib2[k][i]))\n",
        "\n",
        "  dist2=sorted(dist2,key=lambda x:x[1],reverse=True)\n",
        "  print(\"Processing...\");\n",
        "  i=0;\n",
        "  while(dist2[i][1]>=0.15 and i<125511):\n",
        "   # print(dist[i],\" \",df3[\"File_Name\"][dist[i][0]].split('\\\\')[-1])\n",
        "    a2.append(df3[\"File_Name\"][dist2[i][0]].split('\\\\')[-1])\n",
        "    i=i+1;\n",
        "  \n",
        "  rel_docs2.append(a2)\n",
        "\n",
        "  print(\"------------------------------------\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjnEPXKx4lKv",
        "colab_type": "code",
        "outputId": "62caf971-4674-4d85-b17c-9691dd7fe9ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "matches=0\n",
        "for i in range(50):\n",
        "  matches=matches+len(set(rel_docs2[i]) & set(actual_rel_docs[i]))\n",
        "\n",
        "print(\"Total Matches: \",matches)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Matches:  104\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDKvLB6A4ndK",
        "colab_type": "code",
        "outputId": "472e325a-560d-4913-dab8-8f11b9793dcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(\"Average Precison: \", matches/125511)\n",
        "print(\"Average Recall: \", matches/653)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average Precison:  0.0008286126315621738\n",
            "Average Recall:  0.15926493108728942\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLTKEQOl7NHg",
        "colab_type": "text"
      },
      "source": [
        "As we can see, no. of matches increased from 97 to 104\n",
        "after implementing Rocchio Algorithm\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Kzes5t27Zuf",
        "colab_type": "text"
      },
      "source": [
        "Now for Gamma=0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iO9dozEe7eWk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "beta=0.75\n",
        "gamma=0\n",
        "mod_q=np.zeros((50,376999),dtype='float32')\n",
        "for i in range(50):\n",
        "  if(len(list(set(rel_docs[i]) & set(actual_rel_docs[i])))>0): # checking no. of matches > 0 or not\n",
        "    total_rel=len(list(set(rel_docs[i]) & set(actual_rel_docs[i])));\n",
        "    total_non_rel=125511-total_rel\n",
        "    term=beta/total_rel;\n",
        "    mod_q[i]=np.add(array_q[i],term*dr_rev[i])\n",
        "    mod_q[i]=np.subtract(mod_q[i],(gamma/total_non_rel)*ndr_rev[i])\n",
        "  else:\n",
        "    total_non_rel=125511\n",
        "    mod_q[i]=array_q[i]\n",
        "    mod_q[i]=np.subtract(mod_q[i],(gamma/total_non_rel)*ndr_rev[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9GE2nah7y7d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#finding relevant with the modified query\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "cos_lib2 = cosine_similarity(mod_q,X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euKl7d9h72h0",
        "colab_type": "code",
        "outputId": "297dfd00-928b-46ca-d615-a424dc8c8989",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "rel_docs2=[] # to store relev\n",
        "p=0;\n",
        "for k in range(0,50):\n",
        "  dist2=[]\n",
        "  a2=[] # to store relev\n",
        "  b2=[] # actual rel\n",
        "  for i in range(len(cos_lib2[k])):\n",
        "    dist2.append((i,cos_lib2[k][i]))\n",
        "\n",
        "  dist2=sorted(dist2,key=lambda x:x[1],reverse=True)\n",
        "  print(\"Processing...\");\n",
        "  i=0;\n",
        "  while(dist2[i][1]>=0.15 and i<125511):\n",
        "   # print(dist[i],\" \",df3[\"File_Name\"][dist[i][0]].split('\\\\')[-1])\n",
        "    a2.append(df3[\"File_Name\"][dist2[i][0]].split('\\\\')[-1])\n",
        "    i=i+1;\n",
        "  \n",
        "  rel_docs2.append(a2)\n",
        "\n",
        "  print(\"------------------------------------\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEZsUqCS77qI",
        "colab_type": "code",
        "outputId": "04488a1c-a305-48e9-9dbc-38005be287ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "matches=0\n",
        "for i in range(50):\n",
        "  matches=matches+len(set(rel_docs2[i]) & set(actual_rel_docs[i]))\n",
        "\n",
        "print(\"Total Matches: \",matches)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Matches:  104\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXoZ36Zp7-2x",
        "colab_type": "code",
        "outputId": "8be66223-c1e3-4a71-f378-2e3b78e44dfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(\"Average Precison: \", matches/125511)\n",
        "print(\"Average Recall: \", matches/653)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average Precison:  0.0008286126315621738\n",
            "Average Recall:  0.15926493108728942\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ut7s7Pvx8D_i",
        "colab_type": "text"
      },
      "source": [
        "We observe that no. of matches do not increase after\n",
        "changing gamma to 0"
      ]
    }
  ]
}