{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LabAssignment6_qword4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D84azbgqbfl_",
        "colab_type": "text"
      },
      "source": [
        "**Approach: Query Expansion + Word2Vec + Rochio + gamma= 0**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfqB6yLQaUsK",
        "colab_type": "code",
        "outputId": "a27c5bbf-0cff-4d5e-8121-f457a4a0024e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtvVL_-Kan2-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv('drive/My Drive/dataset.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRwBdj8EatEH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "dfq=pd.read_csv('drive/My Drive/dataset_query_exp.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlxScRo2a0iN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.test.utils import common_texts, get_tmpfile\n",
        "from gensim.models import Word2Vec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLSWbdZ9a4qX",
        "colab_type": "code",
        "outputId": "55444753-a89f-4fb7-d95b-822125318d61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "sent=[]\n",
        "for i in range(125511):\n",
        "  if(i%10000==0):\n",
        "    print(i)\n",
        "  tokens=df[\"Tokens\"][i][1:len(df[\"Tokens\"][i])-2]\n",
        "  tokens_list=tokens.split(', ')\n",
        "  for i in range(len(tokens_list)):\n",
        "    tokens_list[i]=tokens_list[i][1:len(tokens_list[i])-1]\n",
        "  sent.append(tokens_list)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "10000\n",
            "20000\n",
            "30000\n",
            "40000\n",
            "50000\n",
            "60000\n",
            "70000\n",
            "80000\n",
            "90000\n",
            "100000\n",
            "110000\n",
            "120000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOfne5K5a9ZA",
        "colab_type": "code",
        "outputId": "1eaea66a-7fa8-4272-c356-1f10ae884dee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(sent))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "125511\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcIkS9_PbIT7",
        "colab_type": "text"
      },
      "source": [
        "**Word embedding using SkipGram Technique**\n",
        "\n",
        "Window size is taken as 2 , Dimension: 100"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59eeUvibbDnK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.test.utils import common_texts, get_tmpfile\n",
        "from gensim.models import Word2Vec\n",
        "model = Word2Vec(sent, size=100, window=2, min_count=1,sg=1) #using skipgram technique"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qStRT1KbSHr",
        "colab_type": "code",
        "outputId": "d2cf10c1-686f-4dcf-aae6-1807ca3d17b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "model.save(\"word2vec.model\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:410: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QO9P_wZvp5_",
        "colab_type": "code",
        "outputId": "5a08762d-0a86-4f8d-8695-42bee45e1d56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "model=Word2Vec.load(\"drive/My Drive/word2vec.model\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:410: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1cJg4Q-uzul",
        "colab_type": "code",
        "outputId": "570ac1fa-6822-423c-d677-29858001188c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model.train(sent,total_examples=125511,epochs=4)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(129914225, 131597408)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCXAjt0ax0Oi",
        "colab_type": "code",
        "outputId": "d8707e2e-201d-4cda-bf2d-aeb2c219d52c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "sent_q=[]\n",
        "for i in range(50):\n",
        "  if(i%5==0):\n",
        "    print(i)\n",
        "  tokens=dfq[\"Tokens\"][i][1:len(dfq[\"Tokens\"][i])-1]\n",
        "  tokens_list=tokens.split(', ')\n",
        "  for i in range(len(tokens_list)):\n",
        "    tokens_list[i]=tokens_list[i][1:len(tokens_list[i])-1]\n",
        "  sent_q.append(tokens_list)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "5\n",
            "10\n",
            "15\n",
            "20\n",
            "25\n",
            "30\n",
            "35\n",
            "40\n",
            "45\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xqkV4B8x4yT",
        "colab_type": "code",
        "outputId": "0adc093c-c082-470c-e643-da76f747572f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "model.wv[\"reason\"] #Sample word vector of 100 dimensions"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.29024836,  0.1606922 ,  0.52632654, -0.1637964 ,  0.03614322,\n",
              "       -0.49315777, -0.22694942,  0.2694871 ,  0.45510322,  0.24887332,\n",
              "        0.09076   , -0.19231062,  0.21659519, -0.1800657 ,  0.37272257,\n",
              "       -0.30173963,  0.46155885, -0.3380218 , -0.34793428,  0.30021107,\n",
              "        0.13928668, -0.37237358,  0.67735475, -0.41021997, -0.17133668,\n",
              "       -0.7945007 ,  0.29764795, -0.26591083, -0.15248977, -0.35347056,\n",
              "       -0.3059114 , -0.00502704,  0.12856673,  0.06625283, -0.15359287,\n",
              "        0.263658  , -0.2502284 , -0.31511596,  0.1963704 ,  0.3382178 ,\n",
              "        0.44306117,  0.13616435, -0.00379117, -0.18723637, -0.06207887,\n",
              "        0.14326905, -0.5428333 ,  0.58212566, -0.34781802,  0.04669193,\n",
              "       -0.7346095 , -0.31885302, -0.06603304,  0.14635526,  0.04139513,\n",
              "       -0.14362943,  0.2978085 ,  0.15617462,  0.3285208 ,  0.76740634,\n",
              "       -0.05319729, -0.20620589,  0.18436311,  0.21690753,  0.55841845,\n",
              "        0.14592141,  0.25610292,  0.14462425,  0.16700995, -0.2652604 ,\n",
              "        0.09283444,  0.31196496,  0.303552  , -0.60412765, -0.20332827,\n",
              "        0.45624185, -0.3423536 ,  0.06128085,  0.17255792,  0.58486545,\n",
              "       -0.531557  ,  0.04361728, -0.44939795,  0.70769495, -0.09685597,\n",
              "        0.28439078,  0.4404162 , -0.26742133, -0.1429895 , -0.22158512,\n",
              "       -0.49619448,  0.15035225, -0.20117882, -0.02672142,  0.8207162 ,\n",
              "        0.7154171 , -0.12186931, -0.26071757,  0.36823618,  0.44338024],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHTxL7Z_x9H9",
        "colab_type": "code",
        "outputId": "9123877b-5b74-4ae3-e2a0-08a590ce1b43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "# calculating vectors for each doc\n",
        "\n",
        "import numpy as np\n",
        "doc_rep=np.zeros((125511,100),dtype='float32')\n",
        "for i in range(125511):\n",
        "  docs=sent[i]\n",
        "  no_of_words=len(docs)\n",
        "  word_rep=[]\n",
        "  for x in docs:\n",
        "    word_rep.append(model.wv[x]);\n",
        "  word_rep_arr=np.array(word_rep)\n",
        "  if(i%10000==0):\n",
        "    print(word_rep_arr.shape)\n",
        "    print(i)\n",
        "  doc_rep[i]=np.average(word_rep_arr,axis=0)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(111, 100)\n",
            "0\n",
            "(177, 100)\n",
            "10000\n",
            "(167, 100)\n",
            "20000\n",
            "(178, 100)\n",
            "30000\n",
            "(157, 100)\n",
            "40000\n",
            "(79, 100)\n",
            "50000\n",
            "(280, 100)\n",
            "60000\n",
            "(170, 100)\n",
            "70000\n",
            "(138, 100)\n",
            "80000\n",
            "(303, 100)\n",
            "90000\n",
            "(98, 100)\n",
            "100000\n",
            "(199, 100)\n",
            "110000\n",
            "(411, 100)\n",
            "120000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AAOnfmuyDX2",
        "colab_type": "code",
        "outputId": "2df4bfac-01e6-4b16-876d-a51a49e36dd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(doc_rep.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(125511, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CF9YLtX0yoyH",
        "colab_type": "code",
        "outputId": "e16795af-4353-47c3-f4ba-136d392e03f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "source": [
        "# calculating vectors for each query \n",
        "import numpy as np\n",
        "query_rep=np.zeros((50,100),dtype='float32')\n",
        "init=np.zeros((1,100),dtype='float32') # for words not present in trained model\n",
        "p=0;\n",
        "for i in range(50):\n",
        "  #if(i==11 or i==25):\n",
        "   # continue\n",
        "  query=sent_q[i]\n",
        "  no_of_words=len(query)\n",
        "  q_rep=[]\n",
        "  for x in query:\n",
        "    try:\n",
        "      q_rep.append(model.wv[x]);\n",
        "    except:\n",
        "      q_rep.append(init)\n",
        "  q_rep_arr=np.array(q_rep)\n",
        "  print(i)\n",
        "  query_rep[p]=np.average(q_rep_arr,axis=0)\n",
        "  p=p+1\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYlOxex3ywl2",
        "colab_type": "code",
        "outputId": "deb9531a-1370-41a7-dc18-ab8567f4f7ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(query_rep.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4sbEGEqy1r2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "cos_lib = cosine_similarity(query_rep,doc_rep)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrNHol90zWmK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "df3=pd.read_csv('drive/My Drive/file_names.csv')\n",
        "\n",
        "import pandas as pd\n",
        "df4=pd.read_csv('drive/My Drive/relevant_docs.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awpmW1VjWWGS",
        "colab_type": "text"
      },
      "source": [
        "Note: **Threshold has been taken as 0.83**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdpAaQVUy_zw",
        "colab_type": "code",
        "outputId": "8649ce35-619e-4580-8e00-88410d8c2a4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "dist=[]\n",
        "rel_docs=[] # to store relev\n",
        "actual_rel_docs=[] # actual rel\n",
        "rel_docs_ids=[] # to store indices of rel doc vectors\n",
        "p=0;\n",
        "for k in range(0,50):\n",
        "  dist=[]\n",
        "  a=[] # to store relev\n",
        "  b=[] # actual rel\n",
        "  ai=[] # to store indices of relev\n",
        "  for i in range(len(cos_lib[k])):\n",
        "    dist.append((i,cos_lib[k][i]))\n",
        "\n",
        "  dist=sorted(dist,key=lambda x:x[1],reverse=True)\n",
        "  print(\"Processing...\");\n",
        "  i=0;\n",
        "  while(dist[i][1]>=0.83 and i<125511):\n",
        "   # print(dist[i],\" \",df3[\"File_Name\"][dist[i][0]].split('\\\\')[-1])\n",
        "    a.append(df3[\"File_Name\"][dist[i][0]].split('\\\\')[-1])\n",
        "    ai.append(dist[i][0])\n",
        "    i=i+1;\n",
        "  \n",
        "  print(\"-----------\")\n",
        "  \n",
        "  print(\"Actual Relevant docs: \")\n",
        "  mdf=(df4[df4[\"Id\"]==k+76])\n",
        "  #print(mdf)\n",
        "  #print(len(mdf))\n",
        "  \n",
        "  for i in range(len(mdf)):\n",
        "    b.append(mdf[\"Doc_Name\"][p])\n",
        "    #print(mdf[\"Doc_Name\"][p])\n",
        "    p=p+1;\n",
        "  rel_docs.append(a)\n",
        "  actual_rel_docs.append(b) # actual rel\n",
        "  rel_docs_ids.append(ai)\n",
        "  print(\"------------------------------------\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n",
            "Processing...\n",
            "-----------\n",
            "Actual Relevant docs: \n",
            "------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTYQlTzI5GQL",
        "colab_type": "code",
        "outputId": "e73c426f-2f09-479e-ff10-668105df0f9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "source": [
        "matches=0\n",
        "for i in range(50):\n",
        "  print(len(actual_rel_docs[i]),\" \",len(set(rel_docs[i]) & set(actual_rel_docs[i])))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5   4\n",
            "20   6\n",
            "3   2\n",
            "4   0\n",
            "8   3\n",
            "6   5\n",
            "23   21\n",
            "9   3\n",
            "3   2\n",
            "22   15\n",
            "7   7\n",
            "9   7\n",
            "22   20\n",
            "47   26\n",
            "5   5\n",
            "12   0\n",
            "38   0\n",
            "19   15\n",
            "25   2\n",
            "11   4\n",
            "3   3\n",
            "22   16\n",
            "5   0\n",
            "3   1\n",
            "21   6\n",
            "13   12\n",
            "17   0\n",
            "7   3\n",
            "8   6\n",
            "13   13\n",
            "4   0\n",
            "14   14\n",
            "11   7\n",
            "10   7\n",
            "11   2\n",
            "16   0\n",
            "17   0\n",
            "14   0\n",
            "8   5\n",
            "19   2\n",
            "10   5\n",
            "1   1\n",
            "10   7\n",
            "7   0\n",
            "12   11\n",
            "21   0\n",
            "20   17\n",
            "19   9\n",
            "7   1\n",
            "13   0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kT_VTGLYGXXX",
        "colab_type": "code",
        "outputId": "e6b58702-48d1-49a9-fcff-655521810618",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "matches=0\n",
        "for i in range(50):\n",
        "  matches=matches+len(set(rel_docs[i]) & set(actual_rel_docs[i]))\n",
        "\n",
        "print(\"Total Matches: \",matches)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Matches:  295\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTbmzLgBJwth",
        "colab_type": "code",
        "outputId": "328773b4-3e44-4b17-bc22-2715042574a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(list(set(rel_docs[0]) & set(actual_rel_docs[0])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['1070602_nation_story_7865940.utf8', '1070603_nation_story_7869357.utf8', '1040901_nation_story_3702283.utf8', '1070611_nation_story_7906812.utf8', '1070530_nation_story_7849973.utf8']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCFgALFpI_fk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "df5=pd.read_csv('drive/My Drive/file_names_new.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXrS4hypJJlK",
        "colab_type": "code",
        "outputId": "341dd020-b430-463d-8669-a322e5e720cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 955
        }
      },
      "source": [
        "dr_rev=np.zeros((50,100),dtype='float32')\n",
        "ndr_rev=np.zeros((50,100),dtype='float32')\n",
        "for i in range(50):\n",
        "  dr=[]\n",
        "  ndr=[]\n",
        "  print(\"processing\")\n",
        "  matched_files=list(set(rel_docs[i]) & set(actual_rel_docs[i]))\n",
        "  for k in range(125511):\n",
        "    if(df5[\"File_Name\"][k] in matched_files):\n",
        "      dr.append(doc_rep[k]) # storing relevant vectors \n",
        "    else:\n",
        "      ndr.append(doc_rep[k]) # storing non relevant vectors\n",
        "  \n",
        "  dr_arr=np.array(dr) # conversion into array\n",
        "  ndr_arr=np.array(ndr)\n",
        "  dr_rev[i]=np.average(dr_arr,axis=0) #finding average of all relevant doc vectors\n",
        "  ndr_rev[i]=np.average(ndr_arr,axis=0)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/lib/function_base.py:393: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis)\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n",
            "processing\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vG-YcEdOOmk",
        "colab_type": "code",
        "outputId": "bf682909-f2a7-406d-dd18-d13af0d1765e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "print(dr_rev[4])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-0.30261573 -0.17261827  0.31989288 -0.17712684 -0.10863154 -0.317651\n",
            "  0.11150265  0.17496566  0.06815441  0.07477763  0.09860824  0.29610214\n",
            "  0.1285724  -0.16312607  0.16676687 -0.12959039  0.17175451 -0.41663122\n",
            " -0.14525405 -0.10312333 -0.08668302 -0.18375048  0.46141505  0.3374409\n",
            " -0.18595535 -0.4641924  -0.15313874 -0.10973386  0.11181398 -0.38842502\n",
            " -0.09740677  0.01939033 -0.15007903  0.28319854 -0.05891808  0.3110803\n",
            " -0.421836   -0.3134853   0.16279826  0.17262237  0.37702936 -0.0370237\n",
            " -0.06865855  0.24487019 -0.00902329  0.02460778 -0.12523423  0.30941385\n",
            " -0.2596913   0.15122403 -0.36215204 -0.24956112 -0.06604018 -0.28103238\n",
            "  0.06277902 -0.09090327 -0.00172408 -0.01235844  0.16783574  0.26614302\n",
            " -0.03147031 -0.05432379  0.26207146 -0.06184213  0.27167445 -0.06452016\n",
            "  0.15028414  0.0099738   0.40149826 -0.4491867  -0.09249078 -0.15874343\n",
            " -0.00188263 -0.29630286 -0.03253992  0.39026156 -0.08439225  0.09628262\n",
            "  0.05680417  0.22478385 -0.3041623  -0.06260191 -0.07673559  0.2664124\n",
            " -0.09482454  0.0448867   0.44494683 -0.1628634  -0.1529213  -0.13055632\n",
            " -0.3920252  -0.06774934 -0.15440677  0.04492333  0.445234    0.3597485\n",
            " -0.26890665  0.08806352 -0.01021366 -0.21962328]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjk6QRWhN7wz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "beta=0.75\n",
        "gamma=0\n",
        "mod_q=np.zeros((50,100),dtype='float32')\n",
        "for i in range(50):\n",
        "  if(len(list(set(rel_docs[i]) & set(actual_rel_docs[i])))>0): # checking no. of matches > 0 or not\n",
        "    total_rel=len(list(set(rel_docs[i]) & set(actual_rel_docs[i])));\n",
        "    total_non_rel=125511-total_rel\n",
        "    term=beta/total_rel;\n",
        "    mod_q[i]=np.add(query_rep[i],term*dr_rev[i])\n",
        "    #mod_q[i]=np.subtract(mod_q[i],(gamma/total_non_rel)*ndr_rev[i])\n",
        "  else:\n",
        "    mod_q[i]=query_rep[i]\n",
        "    #mod_q[i]=np.subtract(mod_q[i],(gamma/total_non_rel)*ndr_rev[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-YucLgTRsb3",
        "colab_type": "code",
        "outputId": "d71c39ae-32d6-4967-cb0e-bbd3d9bad346",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "print(query_rep[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-1.38826743e-01 -2.89725542e-01  8.91866311e-02 -1.62501857e-01\n",
            " -1.79269329e-01 -2.09240884e-01  8.73422623e-02  2.11404130e-01\n",
            " -1.28635168e-01  8.95918161e-02 -1.47978514e-01  1.16049066e-01\n",
            "  1.10434815e-01 -1.41472727e-01  1.28401235e-01 -2.02566028e-01\n",
            " -7.58671835e-02 -4.02699381e-01 -1.28056323e-02 -8.33550319e-02\n",
            "  2.91001201e-02  3.56562026e-02  6.01795614e-01  1.06458232e-01\n",
            " -2.87494659e-01 -2.08319739e-01  5.17137870e-02 -2.68226445e-01\n",
            "  1.28063008e-01 -1.86850145e-01 -2.50460416e-01  2.74546780e-02\n",
            " -2.07499298e-03  2.00916484e-01 -1.63578197e-01  3.40943635e-01\n",
            " -3.15326452e-01 -2.97441214e-01  6.55261101e-03  1.70179129e-01\n",
            "  1.70377567e-01 -9.92521569e-02 -5.62905110e-02  1.34052247e-01\n",
            "  1.06473885e-01  4.97432053e-02 -4.99299169e-02  1.11714430e-01\n",
            " -7.33399391e-02  1.38946235e-01 -4.99737918e-01 -2.25056544e-01\n",
            "  2.74080075e-02 -2.45268688e-01  2.34320149e-01 -8.40348676e-02\n",
            "  2.38386691e-02  6.02361560e-02 -4.47600223e-02  3.02614152e-01\n",
            "  1.92013962e-04  1.86042234e-01  3.92119229e-01  2.06890684e-02\n",
            "  1.96812227e-01  5.99469282e-02  1.05314262e-01 -9.71121117e-02\n",
            "  2.70754755e-01 -1.42195225e-01 -5.83578534e-02 -1.78799089e-02\n",
            "  2.96495706e-01 -1.03499889e-01 -5.15999720e-02  2.92598814e-01\n",
            " -4.01593037e-02  4.46177796e-02  1.73163012e-01 -6.70246258e-02\n",
            " -2.43924141e-01 -2.61599630e-01 -2.07033947e-01  1.05837628e-01\n",
            " -6.07281215e-02  2.84973513e-02  3.46884787e-01 -6.07325360e-02\n",
            " -1.45753071e-01 -2.68068433e-01 -1.78128034e-01  5.18603288e-02\n",
            " -1.09935202e-01 -2.25509256e-02  7.50967115e-02  2.88022459e-01\n",
            " -4.35534805e-01  1.24162339e-01 -3.78789082e-02 -1.86585143e-01]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJsfQEC2RvmT",
        "colab_type": "code",
        "outputId": "3b2a4ea9-623b-438c-bc74-c2f35fd0763b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "print(mod_q[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-0.17665371 -0.31130284  0.12917325 -0.18464272 -0.19284827 -0.24894726\n",
            "  0.10128009  0.23327483 -0.12011587  0.09893902 -0.13565248  0.15306184\n",
            "  0.12650636 -0.16186349  0.1492471  -0.21876483 -0.05439787 -0.45477828\n",
            " -0.03096239 -0.09624545  0.01826474  0.01268739  0.65947247  0.14863834\n",
            " -0.31073907 -0.26634377  0.03257144 -0.28194317  0.14203976 -0.23540327\n",
            " -0.26263627  0.02987847 -0.02083487  0.2363163  -0.17094296  0.37982866\n",
            " -0.36805594 -0.3366269   0.02690239  0.19175692  0.21750623 -0.10388012\n",
            " -0.06487283  0.16466102  0.10534597  0.05281918 -0.0655842   0.15039116\n",
            " -0.10580135  0.15784924 -0.54500693 -0.2562517   0.01915298 -0.28039774\n",
            "  0.24216753 -0.09539778  0.02362316  0.05869135 -0.02378055  0.33588204\n",
            " -0.00374177  0.17925176  0.42487815  0.0129588   0.23077154  0.05188191\n",
            "  0.12409978 -0.09586538  0.32094204 -0.19834356 -0.0699192  -0.03772284\n",
            "  0.2962604  -0.14053774 -0.05566746  0.34138152 -0.05070833  0.0566531\n",
            "  0.18026353 -0.03892665 -0.28194442 -0.26942486 -0.2166259   0.13913918\n",
            " -0.07258119  0.03410819  0.40250313 -0.08109047 -0.16486824 -0.28438798\n",
            " -0.22713119  0.04339166 -0.12923604 -0.01693551  0.13075095  0.33299103\n",
            " -0.46914813  0.13517028 -0.03915561 -0.21403806]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MakAmpxLT1d3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#finding relevant with the modified query\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "cos_lib2 = cosine_similarity(mod_q,doc_rep)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTcQelMwUYpk",
        "colab_type": "code",
        "outputId": "dadd118f-5ed4-4eee-bed4-82024e28cd8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(cos_lib2.shape)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50, 125511)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arcoUo31UEa6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dist2=[]\n",
        "for i in range(len(cos_lib2[0])):\n",
        "  dist2.append((i,cos_lib2[0][i]))\n",
        "\n",
        "dist2=sorted(dist,key=lambda x:x[1],reverse=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbN3oc_lUkxW",
        "colab_type": "code",
        "outputId": "fc33c0ba-968c-4136-e676-74ab9a6519d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "rel_docs2=[] # to store relev\n",
        "p=0;\n",
        "for k in range(0,50):\n",
        "  dist2=[]\n",
        "  a2=[] # to store relev\n",
        "  b2=[] # actual rel\n",
        "  for i in range(len(cos_lib2[k])):\n",
        "    dist2.append((i,cos_lib2[k][i]))\n",
        "\n",
        "  dist2=sorted(dist2,key=lambda x:x[1],reverse=True)\n",
        "  print(\"Processing...\");\n",
        "  i=0;\n",
        "  while(dist2[i][1]>=0.83 and i<125511):\n",
        "   # print(dist[i],\" \",df3[\"File_Name\"][dist[i][0]].split('\\\\')[-1])\n",
        "    a2.append(df3[\"File_Name\"][dist2[i][0]].split('\\\\')[-1])\n",
        "    i=i+1;\n",
        "  \n",
        "  rel_docs2.append(a2)\n",
        "\n",
        "  print(\"------------------------------------\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n",
            "Processing...\n",
            "------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mV5Mq-BqV0Cx",
        "colab_type": "code",
        "outputId": "332a6fd3-1f3f-4bbb-d8a7-163c07c7c47b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "matches=0\n",
        "for i in range(50):\n",
        "  matches=matches+len(set(rel_docs2[i]) & set(actual_rel_docs[i]))\n",
        "\n",
        "print(\"Total Matches: \",matches)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Matches:  381\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7NIirExWBdm",
        "colab_type": "text"
      },
      "source": [
        "As we can see, no. of matches increased from 295 to 381 after implementing Rocchio Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9f-7AoWYRxb",
        "colab_type": "code",
        "outputId": "543060ce-2d3f-4a65-d439-4f2e1218d103",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(\"Average Precison: \", matches/125511)\n",
        "print(\"Average Recall: \", matches/653)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average Precison:  0.0030355905060114254\n",
            "Average Recall:  0.5834609494640123\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}